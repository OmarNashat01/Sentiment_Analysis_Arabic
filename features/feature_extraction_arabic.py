# -*- coding: utf-8 -*-
"""Feature_Extraction_Arabic

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QUhYIT5psZKKmt7YEWQWdPvH_WefJzBF
"""

# -*- coding: utf-8 -*-
# Import the required libraires
import numpy as np
import pandas as pd




data = pd.read_csv('../data/test_Arabic_tweets_positive.tsv',header=None, sep='\t')

# data = pd.concat([test_neg, test_pos, train_neg, train_pos])
data = data.drop([0],axis=1)
data

import re
# !pip install camel_tools
from camel_tools.tokenizers.word import simple_word_tokenize
from nltk.stem import WordNetLemmatizer
# !pip install arabic-stopwords
import arabicstopwords.arabicstopwords as stp
import nltk
nltk.download('wordnet')
nltk.download('omw-1.4')
  
stopwords = set(stp.stopwords_list())
def clean_review(text):
    text = re.sub("[إأٱآا]", "ا", text)
    text = re.sub("ى", "ي", text)
    text = re.sub("ؤ", "ء", text)
    text = re.sub("ئ", "ء", text)
    text = re.sub("ة", "ه", text)
    noise = re.compile(""" ّ    | # Tashdid
                            َ    | # Fatha
                            ً    | # Tanwin Fath
                            ُ    | # Damma
                            ٌ    | # Tanwin Damm
                            ِ    | # Kasra
                            ٍ    | # Tanwin Kasr
                            ْ    | # Sukun
                            ـ     # Tatwil/Kashida
                        """, re.VERBOSE)
    text = re.sub(noise, '', text)
    text = re.sub(r'(.)\1+', r"\1\1", text) # Remove longation
    text = simple_word_tokenize(text)
    text = " ".join(WordNetLemmatizer().lemmatize(i) for i in text if i not in stopwords)

    return text

data[1] = data[1].apply(lambda x:clean_review(x))
data

# from camel_tools.disambig.mle import MLEDisambiguator
# from camel_tools.tagger.default import DefaultTagger

# from camel_tools.ner import NERecognizer

# ner = NERecognizer.pretrained()
import nltk
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
from textblob import TextBlob

data['POS'] = data[1].apply(lambda x: TextBlob(x).tags)
data

# !pip install camel_tools
# !camel_data -i ner-arabert

from camel_tools.ner import NERecognizer

ner = NERecognizer.pretrained()

data['NER'] = data[1].apply(lambda x: list(zip(x.split(),ner.predict_sentence(x.split()))))

data

pos_dict = {}
for rev in data['POS']:
    for word in rev:
        if word[1] in pos_dict:
            #if word[0] not in word[1]:
            pos_dict[word[1]].add(word[0])
        else:
            pos_dict[word[1]] = set(word[0])

for key in pos_dict:
    pos_dict[key] = list(pos_dict[key])

pos_out = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in pos_dict.items() ]))
pos_out

# !pip install xlwt
# pos_out.to_excel('postagging.xlsx')

ner_dict = {}
for rev in data['NER']:
    for word in rev:
        if word[1] in ner_dict:
            #if word[0] not in word[1]:
            ner_dict[word[1]].add(word[0])
        else:
            ner_dict[word[1]] = set(word[0])

for key in ner_dict:
    ner_dict[key] = list(ner_dict[key])

ner_out = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in ner_dict.items() ]))
ner_out

# !pip install xlwt
# ner_out.to_excel('ner.xlsx')

# !camel_data -i morphology-db-all

# from camel_tools.disambig.mle import MLEDisambiguator
# from camel_tools.tagger.default import DefaultTagger


# mled = MLEDisambiguator.pretrained()
# tagger = DefaultTagger(mled, 'pos')

# tagger.tag('ذهبت الى المدرسة'.split())

